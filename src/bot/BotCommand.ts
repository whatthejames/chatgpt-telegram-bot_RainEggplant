import {Telegraf} from 'telegraf';
import {message} from 'telegraf/filters';
import {ChatGPT} from '../api';
import Keyv from 'keyv';
import {Config} from '../types';
import {getRoleMode} from '../PromptsRole';
import {logWithTime} from '../utils';
import {GlobalConfig, globalConfig} from '../GlobalConfig';
import _ from 'lodash';
import {ExtendedContext} from './BotBase';

export class BotCommand {
  constructor(
    public bot: Telegraf<ExtendedContext>,
    public gpt: ChatGPT,
    public keyv: Keyv,
    public config: Config
  ) {}

  async register() {
    this.bot.help(async (ctx, next) => {
      const completionParamsInfo = this.gpt.getCompletionParams();
      const completionParamsInfoString = completionParamsInfo
        ? `å½“å‰æ¨¡åž‹ä¿¡æ¯\n` +
          `  â€¢ model : ${completionParamsInfo?.model} \n` +
          `  â€¢ temperature : ${completionParamsInfo?.temperature} \n` +
          `  â€¢ top_p : ${completionParamsInfo?.top_p} \n` +
          `  â€¢ frequency_penalty : ${completionParamsInfo?.frequency_penalty} \n` +
          `  â€¢ presence_penalty : ${completionParamsInfo?.presence_penalty} \n` +
          `  â€¢ max_tokens : ${completionParamsInfo?.max_tokens} \n` +
          ''
        : '';
      await ctx.sendMessage(
        'To chat with me, you can:\n' +
          '  â€¢ send messages directly (not supported in groups)\n' +
          `  â€¢ send messages that start with ${this.config.bot.chatCmd}\n` +
          '  â€¢ reply to my last message\n\n' +
          'Command list:\n' +
          `(When using a command in a group, make sure to include a mention after the command, like /help@${this.bot.botInfo?.username}).\n` +
          '  â€¢ /help Show help information.\n' +
          '  â€¢ /reset é‡ç½®åˆ°å…¨æ–°çš„èŠå¤©ä¸Šä¸‹æ–‡.\n' +
          '  â€¢ /reload (admin required) Refresh the ChatGPT session.\n' +
          '  â€¢ /hot_load_prompt_json  çƒ­åŠ è½½prompt.jsonå¼•å¯¼è¯æ–‡ä»¶ï¼Œä¿®æ”¹å¼•å¯¼è¯æ–‡ä»¶æ–‡ä»¶åŽä¸éœ€è¦é‡å¯æ•´ä¸ªæœåŠ¡å•¦.\n' +
          'ç³»ç»Ÿè§’è‰²é…ç½®ï¼ˆSystemMessageå¼•å¯¼è¯ï¼‰\n' +
          '  â€¢ /roles åˆ—å‡ºæ‰€æœ‰è§’è‰² , ç”¨è¿™ä¸ªæŒ‡ä»¤åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è§’è‰².\n' +
          '  â€¢ /role æ˜¾ç¤ºå½“å‰çš„è§’è‰².\n' +
          '  â€¢ /role_info å½“å‰è§’è‰²çš„promptå¼•å¯¼è¯.\n' +
          '  â€¢ /system_custom ä½¿ç”¨ [/system_custom å¼•å¯¼è¯] æ¥è®¾ç½®è‡ªå®šä¹‰(custom)è§’è‰²çš„å¼•å¯¼è¯ï¼Œåœ¨åˆ‡æ¢åˆ°customè§’è‰²æ—¶ä½¿ç”¨è¯¥å¼•å¯¼è¯.\n' +
          '  â€¢ /system_custom_clear æ¸…ç©ºcustomå¼•å¯¼è¯\n' +
          `å½“å‰ä½¿ç”¨çš„è§’è‰²æ˜¯ï¼š ${getRoleMode().getNowRole().role} [ /role_${
            getRoleMode().getNowRole().shortName
          } ]\n` +
          'å¯¹è¯ä¸Šä¸‹æ–‡\n' +
          '  â€¢ /get_context èŽ·å–å½“å‰èŠå¤©ä¸Šä¸‹æ–‡çš„çš„å­˜æ¡£ç‚¹.\n' +
          '  â€¢ /print_save_point [å¼€å…³]åœ¨æ¯ä¸€æ¡æ¶ˆæ¯åŽæ˜¾ç¤ºå­˜æ¡£ç‚¹.\n' +
          '  â€¢ /print_tokens [å¼€å…³]åœ¨æ¯ä¸€æ¡æ¶ˆæ¯åŽæ˜¾ç¤ºå½“å‰çš„tokenæ•°.\n' +
          '  â€¢  â€¢  â€¢ å¯ä»¥é€šè¿‡ç›´æŽ¥å‘é€å­˜æ¡£ç‚¹å‘½ä»¤æ¥å›žåˆ°æŒ‡å®šçš„å¯¹è¯çŠ¶æ€ã€‚\n' +
          '  â€¢  â€¢  â€¢ é»˜è®¤å­˜æ¡£çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ä¿å­˜åœ¨å†…å­˜ä¸­ï¼Œé‡å¯æœåŠ¡åŽå¤±æ•ˆã€‚\n' +
          '  â€¢  â€¢  â€¢ è‹¥redisæ•°æ®åº“å·¥ä½œæ­£å¸¸æ—¶å­˜æ¡£çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ä¼šä¿å­˜åˆ°redisæ•°æ®åº“ï¼ŒæœåŠ¡é‡å¯åŽä»ç„¶å¯ä»¥ä½¿ç”¨ä¿å­˜çš„å­˜æ¡£ç‚¹ã€‚\n' +
          'æœ€å¤§ Tokens è®¾ç½®\n' +
          '  â€¢ /get_max_response_tokens æ˜¾ç¤ºæœ€å¤§å›žç­” tokens.\n' +
          '  â€¢ /set_max_response_tokens è®¾ç½®æœ€å¤§å›žç­” tokens.\n' +
          '  â€¢ /get_max_model_tokens æ˜¾ç¤ºæœ€å¤§æ¨¡åž‹ tokens.\n' +
          '  â€¢ /set_max_model_tokens è®¾ç½®æœ€å¤§æ¨¡åž‹ tokens.\n' +
          '  â€¢  â€¢  â€¢ åœ¨æç¤ºå‰©ä½™tokenä¸è¶³ä»¥ç”Ÿæˆå›žç­”æ—¶å¯ä»¥è°ƒå°max_response_tokenså¹¶å†æ¬¡é‡æ–°å‘é€æé—®æ¥é¿å¼€é™åˆ¶\n' +
          '  â€¢  â€¢  â€¢ è°ƒæ•´max_response_tokensçš„å¤§å°ä¹Ÿä¼šå½±å“å›žç­”çš„ç»“æžœï¼Œè¶Šå°è¶Šå€¾å‘äºŽæ›´ç®€å•çš„æ€è€ƒï¼›è¶Šå¤§è¶Šå€¾å‘äºŽæ›´åŠ å¤æ‚çš„æ€è€ƒã€‚è°ƒå°å¯ä»¥é¿å…è¿‡æ‹Ÿåˆï¼Œè°ƒå¤§å¯ä»¥èŽ·å¾—æ›´å¤æ‚çš„è§’è‰²æ‰®æ¼”æ•ˆæžœã€‚\n' +
          '\n\n' +
          'å½“å‰ç›¸å…³è®¾ç½®\n' +
          `  â€¢ max_response_tokens : ${this.gpt.getMaxResponseTokens()} \n` +
          `  â€¢ max_model_tokens : ${this.gpt.getMaxModelTokens()} \n` +
          `  â€¢ print_save_point : ${globalConfig.printSavePointEveryMessage} \n` +
          `  â€¢ print_tokens : ${globalConfig.printTokensEveryMessage} \n` +
          `  â€¢ role : ${getRoleMode().getNowRole().role} [ /role_${
            getRoleMode().getNowRole().shortName
          } ] \n` +
          completionParamsInfoString +
          ''
      );
    });

    this.bot.command('hot_load_prompt_json', async (ctx, next) => {
      await getRoleMode().loadFromJsonFile();
      await getRoleMode().loadCustomFromStorage();
      await ctx.sendMessage('ok');
    });

    this.bot.command('roles', async (ctx, next) => {
      await ctx.sendMessage(
        'roles \n' +
          `${getRoleMode()
            .getRoles()
            .map((T) => `${T.role} [ /role_${T.shortName} ]`)
            .join('\n')}\n` +
          `now role is ${getRoleMode().getNowRole().role} [ /role_${
            getRoleMode().getNowRole().shortName
          } ]`
      );
    });

    this.bot.command('role', async (ctx, next) => {
      await ctx.sendMessage(
        `now role is ${getRoleMode().getNowRole().role} [ /role_${
          getRoleMode().getNowRole().shortName
        } ]`
      );
    });
    this.bot.command('role_info', async (ctx, next) => {
      await ctx.sendMessage(
        `now role is ${getRoleMode().getNowRole().role} [ /role_${
          getRoleMode().getNowRole().shortName
        } ]`
      );
      const pp = getRoleMode().getNowRolePrompt()
        ? 'prompt:\n' + getRoleMode().getNowRolePrompt()
        : 'no prompt';
      if (pp.length < 4096) {
        await ctx.sendMessage(pp);
      } else {
        // https://stackoverflow.com/a/7033662/3548568
        const l = pp.match(/(.|[\r\n]){1,4000}/g);
        if (l) {
          for (const s of l) {
            await ctx.sendMessage(s);
          }
        }
      }
    });

    this.bot.command('reset', async (ctx, next) => {
      await ctx.sendChatAction('typing');
      await this.gpt.resetThread();
      await ctx.sendMessage(
        'ðŸ”„ The chat thread has been reset. New chat thread started.'
      );
      const userInfo = `@${ctx.from?.username ?? ''} (${ctx.from?.id})`;
      logWithTime(`ðŸ”„ Chat thread reset by ${userInfo}.`);
    });

    this.bot.command('get_context', async (ctx, next) => {
      await ctx.sendMessage(
        'you can use follow cmd to restore conversation\\.\n' +
          'you can restore conversation after server restart only if redis work well\\.\n' +
          `Context: \`/resetContext_${await this.gpt.getContext()}\` `,
        {parse_mode: 'MarkdownV2'}
      );
    });

    const toggleGlobalConfig = async (
      ctx: ExtendedContext,
      globalConfigField: keyof GlobalConfig
    ) => {
      globalConfig[globalConfigField] = !globalConfig[globalConfigField];
      await ctx.sendMessage(
        `now ${globalConfigField} is: ${globalConfig[globalConfigField]}`
      );
      await this.keyv.set(
        `globalConfig:${globalConfigField}`,
        globalConfig[globalConfigField]
      );
    };

    this.bot.command('print_save_point', async (ctx, next) => {
      await toggleGlobalConfig(ctx, 'printSavePointEveryMessage');
    });

    this.bot.command('print_tokens', async (ctx, next) => {
      await toggleGlobalConfig(ctx, 'printTokensEveryMessage');
    });

    this.bot.command('system_custom', async (ctx, next) => {
      let text = ctx.message.text ?? '';
      for (const entity of ctx.message.entities ?? []) {
        if (entity.type == 'bot_command' && entity.offset == 0) {
          text = ctx.message.text?.slice(entity.length).trim() ?? '';
        }
      }
      if (text && text.length > 0) {
        await getRoleMode().setCustom(text);
        await ctx.sendMessage(`ok`);
      } else {
        await ctx.sendMessage(`failed`);
      }
    });

    this.bot.command('system_custom_clear', async (ctx, next) => {
      await getRoleMode().setCustom('');
      await ctx.sendMessage(`ok`);
    });

    this.bot.command('get_max_response_tokens', async (ctx, next) => {
      await ctx.sendMessage(
        `now MaxResponseTokens is ${this.gpt.getMaxResponseTokens()}`
      );
    });

    this.bot.command('reset_max_response_tokens', async (ctx, next) => {
      await this.gpt.setMaxResponseTokens(
        this.config.api.official?.maxResponseTokens || 1000
      );
      return await ctx.sendMessage(
        `ok. now MaxResponseTokens is ${this.gpt.getMaxResponseTokens()}`
      );
    });

    this.bot.command('set_max_response_tokens', async (ctx, next) => {
      let text = ctx.message.text ?? '';
      for (const entity of ctx.message.entities ?? []) {
        if (entity.type == 'bot_command' && entity.offset == 0) {
          text = ctx.message.text?.slice(entity.length).trim() ?? '';
        }
      }
      if (text && text.length > 0) {
        const n = parseInt(text);
        if (_.isSafeInteger(n)) {
          await this.gpt.setMaxResponseTokens(n);
          return await ctx.sendMessage(
            `ok. now MaxResponseTokens is ${this.gpt.getMaxResponseTokens()}`
          );
        }
      }
      await ctx.sendMessage(`failed`);
    });

    this.bot.command('get_max_model_tokens', async (ctx, next) => {
      await ctx.sendMessage(
        `now MaxModelTokens is ${this.gpt.getMaxModelTokens()}`
      );
    });

    this.bot.command('reset_max_model_tokens', async (ctx, next) => {
      await this.gpt.setMaxModelTokens(
        this.config.api.official?.maxModelTokens || 4000
      );
      return await ctx.sendMessage(
        `ok. now MaxModelTokens is ${this.gpt.getMaxModelTokens()}`
      );
    });

    this.bot.command('set_max_model_tokens', async (ctx, next) => {
      let text = ctx.message.text ?? '';
      for (const entity of ctx.message.entities ?? []) {
        if (entity.type == 'bot_command' && entity.offset == 0) {
          text = ctx.message.text?.slice(entity.length).trim() ?? '';
        }
      }
      if (text && text.length > 0) {
        const n = parseInt(text);
        if (_.isSafeInteger(n)) {
          await this.gpt.setMaxModelTokens(n);
          return await ctx.sendMessage(
            `ok. now MaxModelTokens is ${this.gpt.getMaxModelTokens()}`
          );
        }
      }
      await ctx.sendMessage(`failed`);
    });

    this.bot.command('reload', async (ctx, next) => {
      const userInfo = `@${ctx.from?.username ?? ''} (${ctx.from?.id})`;
      if (this.config.bot.userIds.indexOf(ctx.from?.id ?? 0) == -1) {
        await ctx.sendMessage(
          'â›”ï¸ Sorry, you do not have the permission to run this command.'
        );
        logWithTime(
          `âš ï¸ Permission denied for "${'/reload'}" from ${userInfo}.`
        );
      } else {
        await ctx.sendChatAction('typing');
        await this.gpt.refreshSession();
        await ctx.sendMessage('ðŸ”„ Session refreshed.');
        logWithTime(`ðŸ”„ Session refreshed by ${userInfo}.`);
      }
    });

    this.bot.use(async (ctx, next) => {
      if (!ctx.message) {
        return next();
      }
      if (!('text' in ctx.message)) {
        return next();
      }
      if (ctx.message.text.startsWith('/role_')) {
        const ro = ctx.message.text.replace(/^\/role_/, '');
        const rn = getRoleMode().getRolesMap().get(ro);
        if (rn) {
          getRoleMode().setNowRole(rn);
          await ctx.sendMessage(
            `now role is ${getRoleMode().getNowRole().role} [ /role_${
              getRoleMode().getNowRole().shortName
            } ]`
          );
        } else {
          await ctx.sendMessage(
            `invalid role. now role is ${
              getRoleMode().getNowRole().role
            } [ /role_${getRoleMode().getNowRole().shortName} ]`
          );
        }
        // ok, this message we processed
        return;
      }
      if (ctx.message.text.startsWith('/resetContext_')) {
        const old = await this.gpt.getContext();
        const cc = ctx.message.text.replace(/^\/resetContext_/, '');
        if (await this.gpt.resetContext(cc)) {
          await ctx.sendMessage(
            `resetContext ok,\nthe old Context is: \`/resetContext_${old}\` `,
            {parse_mode: 'MarkdownV2'}
          );
        } else {
          await ctx.sendMessage(`resetContext failed.`);
        }
        // ok, this message we processed
        return;
      }
      // no, we are not care about this message
      return next();
    });

    // this.bot.command('cmd', async (ctx, next) => {
    // });
  }
}
